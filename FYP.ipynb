{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FYP.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-FuCWiyzVG6",
        "colab_type": "text"
      },
      "source": [
        "#MAIN\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkV2MGNL2yer",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CS7sZ4gR2rMt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd drive\n",
        "%ls\n",
        "%cd My\\ Drive\n",
        "# %ls\n",
        "%cd 'Hand Tracking'\n",
        "%ls\n",
        "# print('=======================================')\n",
        "# %cd ASL_dataset/\n",
        "# %ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WTr4Wqk5CZX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        },
        "outputId": "a91be27a-4b55-4daa-bbd9-be6aa750af02"
      },
      "source": [
        "!pip install dtaidistance"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting dtaidistance\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/51/d3/9202738edfeb728face004debad59efe9690a44ac8d8494b96b9dc541359/dtaidistance-1.2.3.tar.gz (318kB)\n",
            "\r\u001b[K     |█                               | 10kB 17.2MB/s eta 0:00:01\r\u001b[K     |██                              | 20kB 6.7MB/s eta 0:00:01\r\u001b[K     |███                             | 30kB 6.5MB/s eta 0:00:01\r\u001b[K     |████▏                           | 40kB 5.6MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 51kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 61kB 4.7MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 71kB 4.7MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 81kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 92kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 102kB 4.7MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 112kB 4.7MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 122kB 4.7MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 133kB 4.7MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 143kB 4.7MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 153kB 4.7MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 163kB 4.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 174kB 4.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 184kB 4.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 194kB 4.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 204kB 4.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 215kB 4.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 225kB 4.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 235kB 4.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 245kB 4.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 256kB 4.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 266kB 4.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 276kB 4.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 286kB 4.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 296kB 4.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 307kB 4.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 317kB 4.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 327kB 4.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from dtaidistance) (1.18.5)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (from dtaidistance) (0.29.21)\n",
            "Building wheels for collected packages: dtaidistance\n",
            "  Building wheel for dtaidistance (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dtaidistance: filename=dtaidistance-1.2.3-cp36-cp36m-linux_x86_64.whl size=624188 sha256=2ddb2b2cc6ad7095c32b44f9ac978b33761ab1004e9a6337353a0f3fe4e95755\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/9a/74/42c5b9dc714bb5a70b426df08cc860e6a741bc199004873e1b\n",
            "Successfully built dtaidistance\n",
            "Installing collected packages: dtaidistance\n",
            "Successfully installed dtaidistance-1.2.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4n2XPpUo47eB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "import hand_tracker\n",
        "from dtaidistance import dtw,dtw_ndim\n",
        "import numpy as np\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import pickle\n",
        "import sys\n",
        "import os\n",
        "# from videocapture import take_vid\n",
        "# sys.path.append('/home/rakshak/anaconda3/envs/tensorflow/lib/python3.7/site-packages')\n",
        "\n",
        "VERBOSE = False\n",
        "SHOW_FRAMES = False\n",
        "DISPLAY_LANDMARKS = True\n",
        "NORMALIZATION = False\n",
        "STILL_IMAGE = False\n",
        "ONE_SHOT_LEARNING = False\n",
        "\n",
        "\n",
        "class MainPart:\n",
        "\n",
        "    def hand_point_gen(self, img):\n",
        "\n",
        "        # box_shift determines\n",
        "        palm_model_path = \"models/palm_detection.tflite\"\n",
        "        landmark_model_path = \"models/hand_landmark.tflite\"\n",
        "        anchors_path = \"data/anchors.csv\"\n",
        "        detector = hand_tracker.HandTracker(palm_model_path, landmark_model_path, anchors_path,\n",
        "                           box_shift=0.2, box_enlarge=1, verbose=VERBOSE)\n",
        "        kp, box = detector(img)\n",
        "        if box is not None:\n",
        "            for i in range(len(box)):\n",
        "                for j in range(len(box[0])):\n",
        "                    box[i][j] = int(box[i][j])\n",
        "        return kp,box\n",
        "\n",
        "\n",
        "\n",
        "    def video_process(self, name):\n",
        "        points_list=[]\n",
        "        cap = cv2.VideoCapture(name)\n",
        "        amount_of_frames = cap.get(7)\n",
        "        #print(amount_of_frames)\n",
        "\n",
        "        start_frame_number = int(amount_of_frames*4.5/10)\n",
        "        end_frame_number = int(amount_of_frames*4.3/10)\n",
        "        cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame_number)\n",
        "        #print(name)\n",
        "        first = True\n",
        "        x_shift ,y_shift = 0,0\n",
        "        cnt = 0\n",
        "\n",
        "        while(True) and cnt < amount_of_frames - start_frame_number - end_frame_number:\n",
        "            cnt += 1\n",
        "            # Capture frame-by-frame\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "\n",
        "            if '.mov' in name:\n",
        "                cut_frame = frame.shape[0]//2\n",
        "                frame = frame[:(cut_frame-70), :]\n",
        "            #gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "            \n",
        "            kp,box = self.hand_point_gen(frame[:,:,::-1]) # <=================== change here \n",
        "            normalized_kp = 0\n",
        "            #print(box)\n",
        "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "                break\n",
        "            if kp is not None:\n",
        "                if VERBOSE:\n",
        "                    print(kp.shape)\n",
        "\n",
        "                normalized_kp = kp\n",
        "                if NORMALIZATION:\n",
        "                    if first:\n",
        "                        height, width = frame.shape[:2]\n",
        "                        x_shift = width - ((box[2][0]+box[0][0])//2) # add the shift\n",
        "                        y_shift = height - ((box[2][1]+box[0][1])//2)\n",
        "                        first = False\n",
        "                        temp = kp[:,:]+[y_shift, x_shift]\n",
        "                    normalized_kp = kp[:,:]+[y_shift, x_shift]\n",
        "                points_list.append(normalized_kp)\n",
        "\n",
        "                if DISPLAY_LANDMARKS:\n",
        "                    try:\n",
        "                        cv2.rectangle(frame,(int(box[0][0]),int(box[0][1])),(int(box[2][0]),int(box[2][1])),(0,255,0),3)\n",
        "                        for i in range(len(kp[:,0])):\n",
        "                            if VERBOSE:\n",
        "                                print(kp[i,1],kp[i,0])\n",
        "                            frame[int(kp[i,1]),int(kp[i,0])] = (0,0,255)\n",
        "                            cv2.circle(frame,(int(kp[i,0]),int(kp[i,1])),5,(255,0,0),1)\n",
        "                            cv2.circle(frame,(int(box[0][0]),int(box[0][1])),5,(0,0,255),1)\n",
        "                            cv2.circle(frame,(int(((box[2][0]+box[0][0])//2)),int(((box[2][1]+box[0][1])//2))),5,(0,0,255),1)\n",
        "                            #cv2.circle(frame,(int(box[2][1]),int(box[0][1])),5,(255,0,0),1)\n",
        "                    except Exception as e:\n",
        "                        print(e)\n",
        "\n",
        "                \n",
        "            if SHOW_FRAMES:\n",
        "                cv2.imshow('frame', frame)\n",
        "\n",
        "            if STILL_IMAGE:\n",
        "                break #For still images\n",
        "        # When everything done, release the capture\n",
        "        cap.release()\n",
        "        cv2.destroyAllWindows()\n",
        "        #print(cnt)\n",
        "        return points_list\n",
        "\n",
        "\n",
        "    def load_data(self, list_of_vid_names):\n",
        "        x = list()\n",
        "        for i in list_of_vid_names:\n",
        "            x.append(self.video_process(i))\n",
        "        \n",
        "        for i in range(len(x)):\n",
        "            x[i] = np.array(x[i])\n",
        "        \n",
        "        return x\n",
        "\n",
        "\n",
        "    def change_format(self, x):\n",
        "        vid = np.zeros((21,x.shape[0],2)) # frames,21,2 => 21,frames,2\n",
        "        cnt = 0\n",
        "        for i in range(21):\n",
        "            for j in range(x.shape[0]):\n",
        "                if j == 0:\n",
        "                    shifting = x[j,i]\n",
        "                vid[i,j] = x[j,i] - shifting\n",
        "        return vid\n",
        "\n",
        "    def dis_sep(self, f, s, retain_list=False):\n",
        "        first_vid = self.change_format(f)\n",
        "        second_vid = self.change_format(s)\n",
        "        dis_list = []\n",
        "        for i in range(21):\n",
        "            dis_list.append(dtw_ndim.distance(first_vid[i], second_vid[i]))\n",
        "\n",
        "        if retain_list:\n",
        "            return dis_list\n",
        "\n",
        "        return sum(dis_list)/21\n",
        "\n",
        "    def load_vids_from_paths(self,path, option, custom=False):\n",
        "        print('------------------'+option+'------------------')\n",
        "        path = path+option\n",
        "        paths = self.get_list_of_vids_from_folder(path)\n",
        "        data = self.load_data(paths)\n",
        "\n",
        "        if custom:\n",
        "            classes = [x.rsplit('/', 1)[1].replace('.avi', '') for x in paths]\n",
        "            return data, len(data), classes\n",
        "\n",
        "        return data, len(data)\n",
        "\n",
        "    def customMain(self, a_class_option=None):\n",
        "        \n",
        "        size_of_1 = 0\n",
        "        data1 = []\n",
        "        a_class = ['OTHER', 'BACHELOR', 'AIRPLANE', 'ADULT-TALL'] #,'AND'] #'#ALL']#, 'ALONE']\n",
        "        #a_class = ['A', 'ABANDON', 'ABORTION', 'ABOVE', 'ACCEPT']\n",
        "        #a_class = ['CHILD', 'LITTLE-BIT', 'LONELY', 'OLD', 'TWENTY'] \n",
        "        #a_class = ['OTHER', 'TWENTY', 'OLD', 'AND', 'LITTLE-BIT' ,'BACHELOR'] # robust - 10% of video\n",
        "        # 5/7 - robust, 6/8 - okish k=1, \n",
        "        # 8/10 k=1, not robust, 10%\n",
        "        #a_class = ['OTHER', 'TWENTY', 'OLD', 'AND', 'LITTLE-BIT' ,'BACHELOR', 'AIRPLANE', 'LONELY', 'ALONE', '#ALL']\n",
        "        a_class = ['OTHER', 'TWENTY', 'OLD', 'AND', 'LITTLE-BIT' ,'BACHELOR', 'AIRPLANE', 'LONELY', 'ALONE', '#ALL', 'A']#, 'CHILD', 'THINK', 'PLEASE']\n",
        "        #a_class = ['OTHER', 'TWENTY', 'AND', 'OLD' ,'BACHELOR', 'AIRPLANE', 'LONELY', 'ALONE', '#ALL', 'A', 'THINK', 'PLEASE']\n",
        "        if not hasattr(self, 'loaded_data'):\n",
        "            self.loaded_data_output =  []\n",
        "            self.loaded_data = []\n",
        "\n",
        "            for index, option1 in enumerate(a_class):\n",
        "                data1, size_of_1 = self.load_vids_from_paths('/home/rakshak/Desktop/FYP/ASL_dataset/', option1)\n",
        "                self.loaded_data_output = self.loaded_data_output + [index]*size_of_1 \n",
        "                \n",
        "\n",
        "                self.loaded_data = self.loaded_data + data1\n",
        "\n",
        "        for_saving = dict()\n",
        "        for_saving['Classes'] = a_class\n",
        "        for_saving['loaded_data'] = self.loaded_data\n",
        "        for_saving['loaded_data_output'] = self.loaded_data_output\n",
        "\n",
        "        if True:\n",
        "            with open('train_for_gsss.pkl', 'wb') as fp:\n",
        "                pickle.dump(for_saving, fp)\n",
        "\n",
        "        for i in range(len(a_class)):\n",
        "            print('Class '+str(i)+'is '+a_class[i])\n",
        "\n",
        "        print('------------------'+'Loaded Data One Hot'+'------------------')\n",
        "        print(self.loaded_data_output)\n",
        "        print('------------------'+'--------------------'+'------------------')\n",
        "\n",
        "        if a_class_option:\n",
        "            a_class = [a_class[a_class_option]]\n",
        "\n",
        "        self.run(a_class, self.loaded_data, self.loaded_data_output)\n",
        "\n",
        "    def customKNN(self, test_data, loaded_data, loaded_data_output):\n",
        "        values = []\n",
        "        for i in loaded_data:\n",
        "            values.append(self.dis_sep(test_data, i, retain_list=False))\n",
        "        ans = [x for _,x in sorted(zip(values, loaded_data_output))]\n",
        "        return ans\n",
        "        \n",
        "\n",
        "    def run(self, a_class, loaded_data, loaded_data_output, real_time=False, real_time_data=None):\n",
        "        ans_map = dict()\n",
        "\n",
        "        if not real_time:\n",
        "            for j in range(len(a_class)):\n",
        "                expected = a_class[j]\n",
        "                name_test = {'A':'Naomi',\n",
        "                               'BACHELOR': 'Liz_2',\n",
        "                                'AIRPLANE': 'Lana',\n",
        "                                'OTHER': 'Naomi',\n",
        "                                'ADULT-TALL': 'Liz_1',\n",
        "                                'ALONE': 'Dana',\n",
        "                                'AND': 'Liz',\n",
        "                                '#ALL': 'Liz',\n",
        "                                'ABANDON': 'Liz',\n",
        "                                'ABORTION': 'Liz_1',\n",
        "                                'ABOVE': 'Tyler_1',\n",
        "                                'ACCEPT': 'Naomi',\n",
        "                                'CHILD': 'Liz_1',\n",
        "                                'LITTLE-BIT': 'Naomi',\n",
        "                                'LONELY': 'Liz',\n",
        "                                'OLD': 'Liz',\n",
        "                                'TWENTY': 'Naomi',\n",
        "                                'CRASH': 'Liz',\n",
        "                                'ENTER': 'Liz_1',\n",
        "                                'MILLION': 'Liz',\n",
        "                                'THINK': 'Liz',\n",
        "                                'MISTAKE': 'Liz',\n",
        "                                'PLEASE': 'Liz',\n",
        "                                'IDEA': 'Liz'}\n",
        "                test_data = self.load_data(['/home/rakshak/Desktop/FYP/ASL_dataset/##testData/{}/{}.mov'.format(expected, name_test[expected])])\n",
        "                ans_map[expected] = self.customKNN(test_data[0], loaded_data, loaded_data_output)\n",
        "                \n",
        "                #print(expected, sorted(values))\n",
        "        else:\n",
        "            ans_map['Test Data'] = self.customKNN(real_time_data, loaded_data, loaded_data_output)\n",
        "\n",
        "        for i in range(1):\n",
        "            print('=========================================================================================')\n",
        "            k = i*2+1\n",
        "            #print('K is ',k)\n",
        "            #print()\n",
        "            for expected, ans in ans_map.items():\n",
        "                outcome = self.output_class(ans,k, len(a_class))\n",
        "                \n",
        "                \n",
        "\n",
        "                #print(\"Arr\", ans)\n",
        "                print()\n",
        "                if not real_time:\n",
        "                    print(\"Expected Class: \", expected)\n",
        "                if outcome == -1:\n",
        "                    print('Output Class: No clear class')\n",
        "                else:\n",
        "                    print(\"Output Class: \", a_class[outcome])\n",
        "\n",
        "                if real_time:\n",
        "                    return a_class[outcome]\n",
        "\n",
        "    def output_class(self, ans, k, length):\n",
        "        arr = [0]*length\n",
        "        for i in range(k):\n",
        "            arr[ans[i]] += 1\n",
        "\n",
        "        max_index = -1\n",
        "        max_value = 0\n",
        "        draw = False\n",
        "        for i in range(length):\n",
        "            if arr[i] == max_value:\n",
        "                draw = True\n",
        "            if arr[i] > max_value:\n",
        "                max_value = arr[i]\n",
        "                max_index = i\n",
        "                draw = False\n",
        "\n",
        "        if draw:\n",
        "            return -1\n",
        "        return max_index\n",
        "\n",
        "\n",
        "    def get_list_of_vids_from_folder(self, path):\n",
        "\n",
        "        cwd = os.getcwd()\n",
        "        os.chdir(path)\n",
        "        files = os.listdir()\n",
        "        os.chdir(cwd)\n",
        "        vids_path = []\n",
        "        for i in files:\n",
        "            if '.pkl' in i:# or 'Tyler' in i:# or 'Brady' in i:\n",
        "                continue\n",
        "            if '.mov' or '.avi' in i:\n",
        "                #print(i)\n",
        "                p = r'{}'.format(os.path.join(path, i))\n",
        "                vids_path.append(p)\n",
        "                if ONE_SHOT_LEARNING:\n",
        "                    break\n",
        "        return vids_path\n",
        "\n",
        "    def save_as_pickle(self, path, data):\n",
        "        with open(path, 'wb') as fp:\n",
        "            pickle.dump(data, fp)\n",
        "        fp.close()\n",
        "\n",
        "    def load_from_pickle(self, path):\n",
        "        with open(path, 'rb') as fp:\n",
        "            data = pickle.load(fp)\n",
        "        fp.close()\n",
        "        return data\n",
        "\n",
        "    def real_time(self, path=0):\n",
        "        cap = cv2.VideoCapture(path)#'/home/rakshak/Desktop/FYP/proj/FYP src/Hand Tracking/continous_2.avi')#0)\n",
        "        cnt = 0\n",
        "        points_list=[]\n",
        "        fps = 0\n",
        "        train = self.load_from_pickle('train.pkl')\n",
        "\n",
        "        print(train['Classes'])\n",
        "        a_class = train['Classes']\n",
        "        loaded_data = train['loaded_data'] \n",
        "        loaded_data_output = train['loaded_data_output']\n",
        "\n",
        "        while(True):\n",
        "            \n",
        "            if cnt == 5:\n",
        "                if len(points_list) > 5:\n",
        "                    length = len(points_list)\n",
        "                    percent = 0.3\n",
        "                    amount = int(length*(percent/2))\n",
        "                    print('amount', amount)\n",
        "                    print('taken', length-2*amount)\n",
        "                    cut_part = points_list[amount:length-amount]\n",
        "                    self.run(a_class, loaded_data, loaded_data_output, real_time=True, real_time_data=np.array(cut_part))\n",
        "\n",
        "                cnt = 0\n",
        "                points_list=[]\n",
        "                print('Reset')\n",
        "\n",
        "            # Capture frame-by-frame\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "\n",
        "            frame = cv2.resize(frame,(320,240))\n",
        "            gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "            t_frame = np.dstack([gray_frame,gray_frame,gray_frame])\n",
        "            kp,box = self.hand_point_gen(t_frame)#frame[:,:,::-1]) # <=================== change here \n",
        "            normalized_kp = 0\n",
        "            #print(box)\n",
        "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "                break\n",
        "            if kp is not None:\n",
        "                if VERBOSE:\n",
        "                    print(kp.shape)\n",
        "\n",
        "                points_list.append(kp)\n",
        "\n",
        "                if DISPLAY_LANDMARKS:\n",
        "                    try:\n",
        "                        cv2.rectangle(frame,(int(box[0][0]),int(box[0][1])),(int(box[2][0]),int(box[2][1])),(0,255,0),3)\n",
        "                        for i in range(len(kp[:,0])):\n",
        "                            if VERBOSE:\n",
        "                                print(kp[i,1],kp[i,0])\n",
        "                            frame[int(kp[i,1]),int(kp[i,0])] = (0,0,255)\n",
        "                            cv2.circle(frame,(int(kp[i,0]),int(kp[i,1])),5,(255,0,0),1)\n",
        "                            cv2.circle(frame,(int(box[0][0]),int(box[0][1])),5,(0,0,255),1)\n",
        "                            cv2.circle(frame,(int(((box[2][0]+box[0][0])//2)),int(((box[2][1]+box[0][1])//2))),5,(0,0,255),1)\n",
        "                            #cv2.circle(frame,(int(box[2][1]),int(box[0][1])),5,(255,0,0),1)\n",
        "                    except Exception as e:\n",
        "                        print(e)\n",
        "            else:\n",
        "                cnt += 1\n",
        "\n",
        "                \n",
        "            cv2.imshow('frame', frame)\n",
        "\n",
        "        # When everything done, release the capture\n",
        "        cap.release()\n",
        "        cv2.destroyAllWindows()\n",
        "        #print(cnt)\n",
        "        return points_list\n",
        "\n",
        "    def custom_vids(self):\n",
        "        train = self.load_from_pickle('/content/drive/My Drive/train_for_gsss.pkl')#'train_normal.pkl')\n",
        "\n",
        "        for index,classes in enumerate(train['Classes']):\n",
        "            print(classes, index)\n",
        "        a_class = train['Classes']\n",
        "        loaded_data = train['loaded_data'] \n",
        "        loaded_data_output = train['loaded_data_output']\n",
        "\n",
        "        test_data, size_of, classes = self.load_vids_from_paths('/content/drive/My Drive/', 'custom_test', custom=True)\n",
        "        recorder = dict()\n",
        "        print(classes)\n",
        "        for index, data in enumerate(test_data):\n",
        "            expected_class = classes[index].split('_')[0]\n",
        "            print(\"Expected Class:\", classes[index])#expected_class)\n",
        "            ans = self.run(a_class, loaded_data, loaded_data_output, real_time=True, real_time_data=data)\n",
        "            print()\n",
        "\n",
        "            if expected_class in recorder:\n",
        "                recorder[expected_class].append(ans.lower())\n",
        "            else:\n",
        "                recorder[expected_class] = [ans.lower()]\n",
        "        print()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        class_wise_output = dict()\n",
        "        for expected, result in recorder.items():\n",
        "            print(expected, result)\n",
        "            correct += result.count(expected)\n",
        "            total += len(result)\n",
        "\n",
        "            class_wise_output[expected] = dict()\n",
        "            class_wise_output[expected]['Correct'] = result.count(expected)\n",
        "            class_wise_output[expected]['False Positive'] = len(result) - class_wise_output[expected]['Correct']\n",
        "\n",
        "        print(class_wise_output)\n",
        "\n",
        "        print('gesture correct false-positive acc')\n",
        "        for gesture in class_wise_output.keys():\n",
        "            tot = class_wise_output[gesture]['Correct'] + class_wise_output[gesture]['False Positive']\n",
        "            print(gesture, class_wise_output[gesture]['Correct'], class_wise_output[gesture]['False Positive'], ((class_wise_output[gesture]['Correct']/tot)*100) )\n",
        "\n",
        "\n",
        "        print(\"Acc\", ((correct/total)*100))\n",
        "\n",
        "    def custom_capture(self):\n",
        "        train = self.load_from_pickle('train_normal.pkl')\n",
        "\n",
        "        print(train['Classes'])\n",
        "        a_class = train['Classes']\n",
        "        loaded_data = train['loaded_data'] \n",
        "        loaded_data_output = train['loaded_data_output']\n",
        "        print(loaded_data_output)\n",
        "\n",
        "        ok = 'n'\n",
        "        name = input('Enter name of vid\\n')\n",
        "\n",
        "        while ok != 'y':\n",
        "            take_vid(name)\n",
        "\n",
        "            data = self.load_data(['/home/rakshak/Desktop/FYP/proj/FYP src/Hand Tracking/'+name+'.avi'])\n",
        "            self.run(a_class, loaded_data, loaded_data_output, real_time=True, real_time_data=data[0])\n",
        "            print()\n",
        "            ok = input('Is it ok?')\n",
        "\n",
        "    def ISL(self):\n",
        "\n",
        "        class_list, output_list, output_mapper = self.GetISLData()\n",
        "        train_dict = {\n",
        "            'class_list': class_list,\n",
        "            'output_list': output_list,\n",
        "            'output_mapper': output_mapper\n",
        "        }\n",
        "        if True:\n",
        "            with open('train_ISL.pkl', 'wb') as fp:\n",
        "                pickle.dump(train_dict, fp)\n",
        "        print(output_list)\n",
        "        print(output_mapper)\n",
        "\n",
        "\n",
        "    def GetISLData(self):\n",
        "        from natsort import natsorted\n",
        "\n",
        "        # vid_list(x) aka class_list => points_list\n",
        "        # output_list\n",
        "\n",
        "        class_list = []\n",
        "        output_list = []\n",
        "        output_mapper = dict()\n",
        "        cnt = -1\n",
        "        starting_path = '/content/drive/My Drive/One Handed/'\n",
        "\n",
        "\n",
        "        for classes in os.listdir(starting_path):\n",
        "            for topName in os.listdir(starting_path+classes):\n",
        "                cnt += 1\n",
        "                output_mapper[topName] = cnt \n",
        "                path = starting_path+classes+'/'+topName+'/Gallery_list/'\n",
        "                print(topName)\n",
        "                for s in os.listdir(path):\n",
        "                    print('        '+s)\n",
        "                    points_list = []\n",
        "                    for frame in natsorted(os.listdir(path+s)):\n",
        "\n",
        "                        #print(classes,s)\n",
        "                        img = cv2.imread(path+s+'/'+frame)\n",
        "\n",
        "                        rame = cv2.resize(img,(320,240))\n",
        "                        # write the flipped frame\n",
        "                        kp,box = self.hand_point_gen(img[:,:,::-1])\n",
        "                        if kp is not None:\n",
        "                            if DISPLAY_LANDMARKS:\n",
        "                                try:\n",
        "                                    cv2.rectangle(img,(int(box[0][0]),int(box[0][1])),(int(box[2][0]),int(box[2][1])),(0,255,0),3)\n",
        "                                    for i in range(21):\n",
        "                                        img[int(kp[i,1]),int(kp[i,0])] = (0,0,255)\n",
        "                                        cv2.circle(img,(int(kp[i,0]),int(kp[i,1])),5,(255,0,0),1)\n",
        "                                        cv2.circle(img,(int(box[0][0]),int(box[0][1])),5,(0,0,255),1)\n",
        "                                        cv2.circle(img,(int(((box[2][0]+box[0][0])//2)),int(((box[2][1]+box[0][1])//2))),5,(0,0,255),1)\n",
        "                                        #cv2.circle(frame,(int(box[2][1]),int(box[0][1])),5,(255,0,0),1)\n",
        "                                except Exception as e:\n",
        "                                    print(e)\n",
        "\n",
        "                            #cv2.imshow('frame',img)\n",
        "                            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "                                break\n",
        "\n",
        "                            points_list.append(kp)\n",
        "\n",
        "                    class_list.append(points_list)\n",
        "                    output_list.append(cnt)\n",
        "\n",
        "\n",
        "                # Release everything if job is finished\n",
        "                cv2.destroyAllWindows()\n",
        "\n",
        "        return class_list, output_list, output_mapper\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "m = MainPart()\n",
        "#m.customMain()\n",
        "#m.real_time('/home/rakshak/Desktop/FYP/proj/FYP src/Hand Tracking/continous_2.avi')#0)\n",
        "#m.custom_vids()\n",
        "#m.custom_capture()\n",
        "m.ISL()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}